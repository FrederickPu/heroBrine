{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'preprocess' from 'spektral.utils' (/Users/mac/Library/Python/3.9/lib/python/site-packages/spektral/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspektral\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m preprocess\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspektral\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GCNConv\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'preprocess' from 'spektral.utils' (/Users/mac/Library/Python/3.9/lib/python/site-packages/spektral/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from spektral.utils import preprocess\n",
    "from spektral.layers import GCNConv\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Load and preprocess the dataset\n",
    "file_path = '/Users/mac/Desktop/abm.csv'  # Path to abm.csv\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Assume 'customer_id', 'transaction_id', and other features exist in the dataset\n",
    "# Create nodes and edges based on relationships (e.g., customer-to-transaction)\n",
    "node_features = df[['amount_cad', 'cash_indicator', 'debit_credit']].fillna(0).values\n",
    "node_labels = (df['is_anomaly'] if 'is_anomaly' in df.columns else np.zeros(len(df))).astype(int)\n",
    "\n",
    "# Map customer and transaction IDs to unique integers\n",
    "node_mapping = {id_: idx for idx, id_ in enumerate(df['customer_id'].unique())}\n",
    "df['mapped_customer_id'] = df['customer_id'].map(node_mapping)\n",
    "\n",
    "# Verify the existence of the 'transaction_id' column and handle it appropriately\n",
    "if 'transaction_id' in df.columns:\n",
    "    # Create edges (example: customer-to-transaction links)\n",
    "    edge_index = np.array([\n",
    "        df['mapped_customer_id'].values,\n",
    "        df['transaction_id'].values  # Replace with actual transaction links if needed\n",
    "    ])\n",
    "else:\n",
    "    # If 'transaction_id' does not exist, create a dummy edge_index for demonstration\n",
    "    print(\"'transaction_id' column not found. Creating dummy edges.\")\n",
    "    edge_index = np.array([\n",
    "        df['mapped_customer_id'].values,\n",
    "        np.random.randint(0, len(df), len(df))  # Randomly generated transaction IDs for demo purposes\n",
    "    ])\n",
    "\n",
    "# Step 2: Preprocess the graph data\n",
    "edge_index = preprocess.adjacency_matrix(edge_index)  # Convert to adjacency matrix\n",
    "\n",
    "# Convert to TensorFlow compatible format\n",
    "x = tf.convert_to_tensor(node_features, dtype=tf.float32)\n",
    "y = tf.convert_to_tensor(node_labels, dtype=tf.int32)\n",
    "edge_index = tf.convert_to_tensor(edge_index, dtype=tf.int32)\n",
    "\n",
    "# Step 3: Define the Graph CNN model (TensorFlow version)\n",
    "class GCN(tf.keras.Model):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(hidden_dim)\n",
    "        self.conv2 = GCNConv(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, edge_index = inputs\n",
    "        x = self.conv1([x, edge_index])\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv2([x, edge_index])\n",
    "        return x\n",
    "\n",
    "# Step 4: Initialize model, optimizer, and loss\n",
    "model = GCN(input_dim=x.shape[1], hidden_dim=16, output_dim=len(np.unique(y)))\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Step 5: Train the model\n",
    "def train_step(x, edge_index, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model([x, edge_index])\n",
    "        loss = loss_fn(y, logits)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "# Step 6: Test the model\n",
    "def test_step(x, edge_index, y):\n",
    "    logits = model([x, edge_index])\n",
    "    pred = tf.argmax(logits, axis=-1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(pred, y), tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, 101):\n",
    "    loss = train_step(x, edge_index, y)\n",
    "    if epoch % 10 == 0:\n",
    "        accuracy = test_step(x, edge_index, y)\n",
    "        print(f\"Epoch {epoch:03d}, Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
