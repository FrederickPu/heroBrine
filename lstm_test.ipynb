{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "OVZ5fQtJWYp3",
      "metadata": {
        "id": "OVZ5fQtJWYp3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_sequences_from_csv(filename, sequence_length=10):\n",
        "  # Load dataset\n",
        "  data = pd.read_csv(filename)  # Replace with your dataset path\n",
        "\n",
        "  # Fill missing values\n",
        "  # data['province'] = data['province'].fillna('unknown')\n",
        "  #data['city'] = data['city'].fillna('unknown')\n",
        "\n",
        "  # Encode categorical variables\n",
        "  categorical_columns = ['debit_credit']\n",
        "  for col in categorical_columns:\n",
        "      data[col] = LabelEncoder().fit_transform(data[col])\n",
        "\n",
        "  # Normalize numerical variables\n",
        "  scaler = MinMaxScaler()\n",
        "  data['amount_cad'] = scaler.fit_transform(data[['amount_cad']])\n",
        "\n",
        "  # Combine transaction_date and transaction_time into a single datetime feature\n",
        "  if 'transaction_time' in data.columns:\n",
        "    data['transaction_datetime'] = pd.to_datetime(data['transaction_date'] + ' ' + data['transaction_time'])\n",
        "    data = data.sort_values(by=['customer_id', 'transaction_datetime'])\n",
        "  else:\n",
        "    data = data.sort_values(by=['customer_id', 'transaction_date'])\n",
        "\n",
        "  # Drop unused columns\n",
        "  columns_to_keep = ['customer_id', 'amount_cad', 'debit_credit']\n",
        "  data = data[columns_to_keep]\n",
        "\n",
        "  # Group by customer_id and create sequences\n",
        "  grouped = data.groupby('customer_id')\n",
        "  sequences = []\n",
        "  for customer_id, group in grouped:\n",
        "      group = group.drop(columns=['customer_id']).values\n",
        "      for i in range(len(group) - sequence_length + 1):\n",
        "          sequences.append(group[i:i+sequence_length])\n",
        "  sequences = np.array(sequences)\n",
        "  return sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e1uWf0PVBxvNhuhevXz8YCbF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e1uWf0PVBxvNhuhevXz8YCbF",
        "outputId": "4e8e121e-05ce-414f-cc54-b38898d2cc94",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mac/Library/Python/3.9/lib/python/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,152</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ repeat_vector_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m17,152\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ repeat_vector_1 (\u001b[38;5;33mRepeatVector\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m8,320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m24,832\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m2\u001b[0m)          │           \u001b[38;5;34m130\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,850</span> (245.51 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m62,850\u001b[0m (245.51 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,850</span> (245.51 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m62,850\u001b[0m (245.51 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1836 - val_loss: 0.0888\n",
            "Epoch 2/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0873 - val_loss: 0.0808\n",
            "Epoch 3/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0800 - val_loss: 0.0748\n",
            "Epoch 4/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0743 - val_loss: 0.0695\n",
            "Epoch 5/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0691 - val_loss: 0.0623\n",
            "Epoch 6/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0625 - val_loss: 0.0552\n",
            "Epoch 7/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0570 - val_loss: 0.0488\n",
            "Epoch 8/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0478 - val_loss: 0.0486\n",
            "Epoch 9/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0446 - val_loss: 0.0433\n",
            "Epoch 10/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0401 - val_loss: 0.0339\n",
            "Epoch 11/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0349 - val_loss: 0.0331\n",
            "Epoch 12/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0319 - val_loss: 0.0290\n",
            "Epoch 13/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0299 - val_loss: 0.0281\n",
            "Epoch 14/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0282 - val_loss: 0.0253\n",
            "Epoch 15/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0257 - val_loss: 0.0458\n",
            "Epoch 16/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0279 - val_loss: 0.0271\n",
            "Epoch 17/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0237 - val_loss: 0.0224\n",
            "Epoch 18/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0218 - val_loss: 0.0239\n",
            "Epoch 19/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0222 - val_loss: 0.0213\n",
            "Epoch 20/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0203 - val_loss: 0.0189\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Threshold: 0.05679099980772268\n",
            "Number of anomalies detected: 69\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "sequence_length = 10\n",
        "sequences = load_sequences_from_csv(\"abm.csv\", sequence_length)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test = train_test_split(sequences, test_size=0.2, random_state=42)\n",
        "\n",
        "# LSTM Autoencoder Model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(64, activation='relu', input_shape=(sequence_length, X_train.shape[2]), return_sequences=True),\n",
        "    tf.keras.layers.LSTM(32, activation='relu', return_sequences=False),\n",
        "    tf.keras.layers.RepeatVector(sequence_length),\n",
        "    tf.keras.layers.LSTM(32, activation='relu', return_sequences=True),\n",
        "    tf.keras.layers.LSTM(64, activation='relu', return_sequences=True),\n",
        "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(X_train.shape[2]))\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, X_train, epochs=20, batch_size=32, validation_split=0.2, shuffle=True)\n",
        "\n",
        "# Reconstruction errors\n",
        "X_test_pred = model.predict(X_test)\n",
        "test_loss = np.mean(np.power(X_test - X_test_pred, 2), axis=(1, 2))\n",
        "\n",
        "# Anomaly detection threshold\n",
        "threshold = np.percentile(test_loss, 95)  # Adjust as needed\n",
        "anomalies = test_loss > threshold\n",
        "\n",
        "print(f\"Threshold: {threshold}\")\n",
        "print(f\"Number of anomalies detected: {np.sum(anomalies)}\")\n",
        "\n",
        "# Suppose your model is defined as 'model'\n",
        "model.save('model_lstm.h5')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KyLbXBtER8KZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyLbXBtER8KZ",
        "outputId": "112cd6bd-bc1b-49d9-8c36-b3d9ceb24b8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 18ms/step - loss: 4.9758e-04 - val_loss: 4.6399e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 18ms/step - loss: 9.5539e-04 - val_loss: 2.3122e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 18ms/step - loss: 3.6410e-04 - val_loss: 1.6483e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 18ms/step - loss: 6.1018e-04 - val_loss: 1.8335e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 19ms/step - loss: 4.4134e-04 - val_loss: 0.0015\n",
            "Epoch 6/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 18ms/step - loss: 7.0897e-04 - val_loss: 1.4931e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 18ms/step - loss: 2.0021e-04 - val_loss: 2.1210e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 19ms/step - loss: 1.7541e-04 - val_loss: 1.3667e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 19ms/step - loss: 9.3998e-04 - val_loss: 1.3430e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 19ms/step - loss: 2.2210e-04 - val_loss: 1.3322e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 19ms/step - loss: 2.6365e-04 - val_loss: 1.2302e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 18ms/step - loss: 1.8291e-04 - val_loss: 1.2774e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 18ms/step - loss: 1.4762e-04 - val_loss: 1.2379e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 18ms/step - loss: 2.1998e-04 - val_loss: 1.1824e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 18ms/step - loss: 1.5576e-04 - val_loss: 1.2333e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 18ms/step - loss: 1.3975e-04 - val_loss: 1.3299e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 18ms/step - loss: 1.8576e-04 - val_loss: 1.1857e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 18ms/step - loss: 1.4027e-04 - val_loss: 1.2159e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 18ms/step - loss: 2.4107e-04 - val_loss: 1.1713e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 18ms/step - loss: 1.3321e-04 - val_loss: 1.4165e-04\n",
            "\u001b[1m1277/1277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step\n",
            "Threshold: 0.00011115491731593637\n",
            "Number of anomalies detected: 2043\n"
          ]
        }
      ],
      "source": [
        "sequences = load_sequences_from_csv(\"cheque.csv\")\n",
        "X_train, X_test = train_test_split(sequences, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model more\n",
        "history = model.fit(X_train, X_train, epochs=20, batch_size=32, validation_split=0.2, shuffle=True)\n",
        "\n",
        "# Reconstruction errors\n",
        "X_test_pred = model.predict(X_test)\n",
        "test_loss = np.mean(np.power(X_test - X_test_pred, 2), axis=(1, 2))\n",
        "\n",
        "# Anomaly detection threshold\n",
        "threshold = np.percentile(test_loss, 95)  # Adjust as needed\n",
        "anomalies = test_loss > threshold\n",
        "\n",
        "print(f\"Threshold: {threshold}\")\n",
        "print(f\"Number of anomalies detected: {np.sum(anomalies)}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "lstm_test.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
